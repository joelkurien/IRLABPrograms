{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab2part1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqo5Wg9oyYs1"
      },
      "source": [
        "import nltk \n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords, gutenberg\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BROTn_uKH3iZ",
        "outputId": "d51ac515-975c-499d-fd56-64cf479f4a00"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "stopWords = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42jdvS30H_9k",
        "outputId": "b53c81f1-365a-4920-d524-45c86847c7ca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nap8ol_fIQEu",
        "outputId": "db1d10da-6ad6-40e6-86eb-9397c8127a95"
      },
      "source": [
        "import csv\n",
        "import sys\n",
        "csv.field_size_limit(sys.maxsize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9223372036854775807"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2NsilL7IkFm",
        "outputId": "735aa3f1-0867-44da-e03d-89903202f9f3"
      },
      "source": [
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOtYYZV-Ir7h"
      },
      "source": [
        "BLOCKSIZE=100000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eXIkUrsVIjr"
      },
      "source": [
        "import re\n",
        "def symbolremoval(word):\n",
        "  return re.sub('[^A-Za-z0-9\\s]+', '', word).lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gU3w08rIxsU"
      },
      "source": [
        "from collections import defaultdict\n",
        "def bsbi():\n",
        "  termdoc_list = defaultdict(list)\n",
        "  with open('gutenberg_data.csv') as csv_file:\n",
        "    next(csv_file)\n",
        "    csv_files = csv.reader(csv_file)\n",
        "    fileno = 0\n",
        "    i = 0\n",
        "    current_block = 0\n",
        "    for row in csv_files:\n",
        "      #creating the term-DocID relation\n",
        "      title, author, link, id, bookshelf, body = row\n",
        "      i+=1\n",
        "      content = body.split()\n",
        "      for word in content:\n",
        "        word = symbolremoval(word)\n",
        "        if word and word not in stopWords:\n",
        "          word = porter.stem(word)\n",
        "          if word not in termdoc_list:\n",
        "            current_block += 1\n",
        "          \n",
        "          if id not in termdoc_list[word]:\n",
        "            termdoc_list[word].append(id)\n",
        "            current_block += 1\n",
        "          #sorting the term-DocID relation and creating its posting lists\n",
        "          if current_block >= BLOCKSIZE:\n",
        "            word_sorted = sorted(termdoc_list.items(), key=lambda x:x[0])\n",
        "            #creating block files\n",
        "            with open(f'./IRLAB/Lab2BLOCK{fileno}.txt', 'w') as myfile:\n",
        "              for id, docs in word_sorted:\n",
        "                myfile.write(id)\n",
        "                for docid in docs:\n",
        "                  myfile.write(f' {docid}')\n",
        "                myfile.write('\\n')\n",
        "            \n",
        "            current_block = 0\n",
        "            termdoc_list.clear()\n",
        "            fileno += 1\n",
        "    print(\"blocks computed\")    \n",
        "\n",
        "    wordsorted = sorted(termdoc_list.items(), key=lambda x:x[0])\n",
        "    if len(wordsorted)>0:\n",
        "      with open(f'./IRLAB/Lab2BLOCK{fileno}.txt', 'w') as myfile:\n",
        "        for id, docs in wordsorted:\n",
        "          myfile.write(id)\n",
        "          for docid in docs:\n",
        "            myfile.write(f' {docid}')\n",
        "          myfile.write('\\n')\n",
        "      current_block = 0\n",
        "      termdoc_list.clear()\n",
        "      fileno += 1     \n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "id": "xeZzw0mbJkYE",
        "outputId": "e19669ac-cbf0-47f0-ad24-1181e7d4b331"
      },
      "source": [
        "bsbi()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 files done\n",
            "23 files done\n",
            "41 files done\n",
            "54 files done\n",
            "67 files done\n",
            "81 files done\n",
            "96 files done\n",
            "116 files done\n",
            "130 files done\n",
            "146 files done\n",
            "157 files done\n",
            "181 files done\n",
            "207 files done\n",
            "220 files done\n",
            "254 files done\n",
            "271 files done\n",
            "280 files done\n",
            "291 files done\n",
            "302 files done\n",
            "332 files done\n",
            "353 files done\n",
            "371 files done\n",
            "387 files done\n",
            "400 files done\n",
            "444 files done\n",
            "456 files done\n",
            "468 files done\n",
            "476 files done\n",
            "488 files done\n",
            "499 files done\n",
            "506 files done\n",
            "509 files done\n",
            "518 files done\n",
            "526 files done\n",
            "533 files done\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7058ea0f4fe4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbsbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-930a771b6d76>\u001b[0m in \u001b[0;36mbsbi\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbolremoval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstopWords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m           \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mporter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-bd2db6f70037>\u001b[0m in \u001b[0;36msymbolremoval\u001b[0;34m(word)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msymbolremoval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^A-Za-z0-9\\s]+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "SRv3bKPmdplQ",
        "outputId": "f24d34e5-d21b-4bb6-ec61-43eff0e14181"
      },
      "source": [
        "#find the block in the disk for adding into priority queue\n",
        "%cd \n",
        "file = [f'./IRLAB/Lab2BLOCK{i}.txt' for i in range(947)]\n",
        "fileseek = [open(i) for i in file]\n",
        "drive.mount('/content/drive')\n",
        "#merging the different block files created\n",
        "#into one merged file using heap queue\n",
        "import heapq\n",
        "\n",
        "#creating a generator such so as to split the words and their doc_ids \n",
        "#in the posting list of each word\n",
        "def decorated_file(f, key):\n",
        "  for word in f:\n",
        "    yield (key(word), word)\n",
        "  \n",
        "files = map(open, file)\n",
        "outfile = open('./IRLAB/Lab2merged.txt', 'w')\n",
        "\n",
        "#spliting the words\n",
        "def key_fn(word):\n",
        "  return word.split(' ',2)[0]\n",
        "\n",
        "wordpresent = ''\n",
        "for line in heapq.merge(*[decorated_file(f, key_fn) for f in files]):\n",
        "  #checking if the word already exists or not\n",
        "  if wordpresent != line[0]:\n",
        "    #if not add the new word to the file\n",
        "    outfile.write(f'\\n{line[1].strip()}')\n",
        "    wordpresent = line[0]\n",
        "  else:\n",
        "    #else append the new data into the word's list\n",
        "    outfile.write(f'{line[1][len(line[0]):].strip()}')\n",
        "for i in fileseek:\n",
        "  i.close()\n",
        "outfile.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-8649244885f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0moutfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./IRLAB/Lab2merged.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#spliting the words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './IRLAB/Lab2merged.txt'"
          ]
        }
      ]
    }
  ]
}